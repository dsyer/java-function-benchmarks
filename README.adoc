[.lead]
In this module we study the effect of various flags and implementation options on startup time for the function invoker.

You can run the benchmarks by cloning this repository next to your clone of `java-function-invoker` (and using the default directory names). If you want to change the locations or names of directories look at the `MainBenchmark` where it creates its state, and change the path to the `java-function-invoker` module. The version label for the jar is also hard coded.

== Results

=== Baseline

Results in seconds (baseline commit `d53434b`, 0.0.1-SNAPSHOT) on hardware "X1 Carbon" Thinkpad (4-core Intel(R) Core(TM) i7-5600U CPU @ 2.60GHz
):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  5.522 ± 0.330   s/op
MainBenchmark.main      norm    ss   10  3.685 ± 0.095   s/op
MainBenchmark.main      expl    ss   10  5.807 ± 0.409   s/op
MainBenchmark.main      fast    ss   10  3.834 ± 0.122   s/op
MainBenchmark.main      main    ss   10  4.044 ± 0.203   s/op
MainBenchmark.main      best    ss   10  2.251 ± 0.108   s/op
```
<1> (base) Fat jar no JVM options (i.e. roughly where we were before any optimizations)
<2> (norm) Fat jar with extended JVM options
<3> (expl) Exploded jar with no JVM options, main class `JarLauncher`
<4> (fast) Exploded jar with extended JVM options, main class `JarLauncher`
<5> (main) Exploded jar with no JVM options, main class from app
<6> (best) Exploded jar with extended JVM options, main class from app

On better hardware "Desktop" (8-core Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  2.889 ± 0.130   s/op
MainBenchmark.main      norm    ss   10  2.727 ± 0.034   s/op
MainBenchmark.main      expl    ss   10  2.907 ± 0.166   s/op
MainBenchmark.main      fast    ss   10  2.808 ± 0.050   s/op
MainBenchmark.main      main    ss   10  2.129 ± 0.082   s/op
MainBenchmark.main      best    ss   10  1.559 ± 0.040   s/op
```

The rest of the data below uses the "X1 Carbon".


=== With Flux Support

Supported but not enabled, so same tests:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  5.451 ± 0.397   s/op
MainBenchmark.main      norm    ss   10  3.801 ± 0.183   s/op
MainBenchmark.main      expl    ss   10  5.896 ± 0.430   s/op
MainBenchmark.main      fast    ss   10  4.019 ± 0.858   s/op
MainBenchmark.main      main    ss   10  4.109 ± 0.163   s/op
MainBenchmark.main      best    ss   10  2.344 ± 0.136   s/op
```

(No regression.)

With a `FluxDoubler` and an isolated classpath:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  7.275 ± 0.516   s/op
MainBenchmark.main      norm    ss   10  5.415 ± 0.061   s/op
MainBenchmark.main      expl    ss   10  7.871 ± 0.483   s/op
MainBenchmark.main      fast    ss   10  5.523 ± 0.124   s/op
MainBenchmark.main      main    ss   10  4.102 ± 0.201   s/op
MainBenchmark.main      best    ss   10  2.315 ± 0.089   s/op
```

Fat jar slower (don't know why). Exploded not that different, maybe even a bit faster.

=== Load Function from Jar

Instead of loading the function from `test-classes` in the `java-function-invoker` would could load from a jar, e.g. the `function-sample-pof` in `spring-cloud-function`.

Baseline (load from a jar, but not use isolated class loader):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  5.479 ± 0.357   s/op
MainBenchmark.main      norm    ss   10  3.702 ± 0.048   s/op
MainBenchmark.main      expl    ss   10  5.847 ± 0.214   s/op
MainBenchmark.main      fast    ss   10  3.803 ± 0.089   s/op
MainBenchmark.main      main    ss   10  3.978 ± 0.276   s/op
MainBenchmark.main      best    ss   10  2.253 ± 0.082   s/op
```

Isolated class loader with function of `Flux`:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  7.406 ± 0.384   s/op
MainBenchmark.main      norm    ss   10  5.438 ± 0.137   s/op
MainBenchmark.main      expl    ss   10  8.026 ± 0.532   s/op
MainBenchmark.main      fast    ss   10  5.614 ± 0.137   s/op
MainBenchmark.main      main    ss   10  4.135 ± 0.353   s/op
MainBenchmark.main      best    ss   10  2.376 ± 0.105   s/op
```

=== Remove the Actuator

The Actuator is pulled in via the Prometheus starter (3rd party). Removing that should speed things up. Results, relative to baseline:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  4.260 ± 0.294   s/op
MainBenchmark.main      norm    ss   10  2.693 ± 0.066   s/op
MainBenchmark.main      expl    ss   10  4.725 ± 0.385   s/op
MainBenchmark.main      fast    ss   10  2.813 ± 0.104   s/op
MainBenchmark.main      main    ss   10  3.115 ± 0.171   s/op
MainBenchmark.main      best    ss   10  1.774 ± 0.074   s/op
```

=== Use the Boot Classpath

What about a class loader with null parent (like the baseline) but with reactor in the boot classpath. In addition to ripping out Actuator:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      base    ss   10  4.457 ± 0.197   s/op
MainBenchmark.main      best    ss   10  1.802 ± 0.055   s/op
```

i.e. just as good startup time. Much simpler code.

=== All Swimming in the Same Soup

Removing the function class loader seems like a valid approach, if it would save some startup time. It wouldn't work for all functions, but it might be a useful option. Here's the result:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.856 ± 0.040   s/op
```

i.e. no improvement. Simpler code, but more complicated build process, and functions have to be available on the classpath when the app starts.

=== Use the Thin Deployer

To support a more Spring Boot native instantiation strategy, we can use the deployer from the [Spring Cloud Function](https://github.com/spring-cloud/spring-cloud-function). It starts a `@SpringBootApplication` in an isolated classloader and registers all the functions it finds there in the main application `FunctionCatalog`. Here's the first attempt:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  3.135 ± 0.209   s/op
```

So it's slower by about 1300ms. 500ms of that is the new function context starting up. The rest is the Thin Deployer resolving dependencies and building a classpath. Should be able to speed that up with a pre-computed `thin.properties`, i.e. using the output from this

```
$ java -jar spring-boot-thin-launcher-1.0.8.BUILD-SNAPSHOT-exec.jar --thin.classpath=properties --thin.archive=~/dev/thin/function/spring-cloud-function-samples/function-sample-pof/target/classes
```

Here's the result:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  2.226 ± 0.138   s/op
```

That closes the gap to 500ms. All of that is still in the deployer so maybe there are some optimizations to do there. If we could launch fat or shaded jars without any need for aether, that would speed things up a lot.

=== Shaded Function Jars and "Native" Spring Context Runner

Instead of depending on the deployer we could observe that some of that code has to be duplicated (instead of generalizing it just to support `Flux<>` functions and a shared parent class loader). So we could just use that code (the `ContextRunner`) to create a Spring Boot application in the `FunctionConfiguration`. The function jars would have to be shaded, at least initially.

Adding that code, but not using the `ContextRunner` (i.e. just doing the same as before, to check for stupid regressions), running from a jar file (`sample-function-pof`):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.826 ± 0.081   s/op
```

(So that looks good.)

Using the `app:classpath` and a `Doubler` (so still not launching Spring):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.811 ± 0.088   s/op
```

Using the `app:classpath` and a `SpringDoubler` (so launching Spring "manually"):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  2.549 ± 0.108   s/op
```

(Adds about 700ms for the second Spring lifecycle.)

Using a jar file (`function-sample-pof`) and a Spring main class:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  2.574 ± 0.096   s/op
```

(About the same.)

== Adding Streams (Pipes)

More dependencies, so we expect things to slow down and they do:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  3.291 ± 0.147   s/op
```

Cf this (with 0.0.2-snapshot, 127 beans, 5453 classes):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.951 ± 0.118   s/op
```

Removing actuator (204 beans, 6271 classes):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  2.856 ± 0.093   s/op
```

If startup time is proportional to classes loaded, we'd expect closer to 2200ms startup for 6271 classes, so there is room for improvement.

== Disabling Streams

Once the streams are on the classpath they take extra time on startup, even if they are not used. We added a "nost" sample where we measure the effect of switching off streams (and Spring Integration) at runtime.

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      nost    ss   10  1.957 ± 0.130   s/op
```

(Almost as fast as without the stream dependencies.)

== Java 9

The function invoker needs some changes to avoid making assumptions about the form of the class loader. Once that is done:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  2.403 ± 0.204   s/op
```

So a bit slower overall. Shared class caches offer some hope to get back a bit of that speed, but it's unlikely to beat the raw Java 8 numbers.

== Disabling Selective Autoconfigs

Small improvements might be possible by disabling selective autconfigs. With 

```
--spring.autoconfigure.exclude=\
  org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,
  org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration
```

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.813 ± 0.080   s/op
```

(It's marginal, but detectable, just about.)

== Remove Web Endpoints

Remove `spring-cloud-function-web` and the stream dependencies on `spring-boot-starter-web`:

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      best    ss   10  1.862 ± 0.253   s/op
```

Similar result from `nweb` sample (with `spring.main.web-environment=false`):

```
Benchmark           (sample)  Mode  Cnt  Score   Error  Units
MainBenchmark.main      nweb    ss   10  1.864 ± 0.084   s/op
```